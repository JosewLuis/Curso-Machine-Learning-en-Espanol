{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices de confusión y métodos de evaluación clásicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre es importante observar la matriz de confusión.<br>\n",
    "Aqui vemos lo que daría lugar a nuestra matriz:\n",
    "<a href=\"https://imgur.com/RyXbseN\"><img src=\"https://i.imgur.com/RyXbseN.png\" title=\"source: imgur.com\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siguiendo la matriz tenemos:<br>\n",
    "\\begin{equation*}\n",
    "    Exactitud=\\frac{TP+TN}{TP+TN+FP+FN}.\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "    Error\\,De\\,Clasificación=\\frac{FP+FN}{TP+TN+FP+FN}.\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "    Recall/Ratio\\,TP=\\frac{TP}{TP+FN}.\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "    Precisión=\\frac{TP}{TP+FP}.\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "    Ratio\\,FP=\\frac{FP}{TN+FP}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego tenemos diversas maneras de trazar nuestra línea:<br>\n",
    "<a href=\"https://imgur.com/9wCAUUp\"><img src=\"https://i.imgur.com/9wCAUUp.png\" title=\"source: imgur.com\" /></a>\n",
    "<a href=\"https://imgur.com/cGdTr6z\"><img src=\"https://i.imgur.com/cGdTr6z.png\" title=\"source: imgur.com\" /></a>\n",
    "<a href=\"https://imgur.com/eQLvgZ6\"><img src=\"https://i.imgur.com/eQLvgZ6.png\" title=\"source: imgur.com\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego esto da lugar a dos modelos:<br>\n",
    "* Orientado a Recall.\n",
    "* Orientado a Precisión.\n",
    "\n",
    "Se denomina $\\textbf{Puntuación F1}$ a la combinación de Precisión y Recall en un número:<br>\n",
    "\\begin{equation*}\n",
    "    F_1=2\\frac{Precisión·Recall}{Precisión+Recall}=\\frac{2TP}{2TP+FN+FP}.\n",
    "\\end{equation*}<br>\n",
    "Se denomina $\\textbf{Puntuación F}$ a la generalización de F1:\n",
    "\\begin{equation*}\n",
    "    F_\\beta=(1+\\beta^2)\\frac{Precisión·Recall}{(\\beta^2Precisión)+Recall}=\\frac{(1+\\beta^2)2TP}{(1+\\beta^2)TP+\\beta·FN+FP}.\n",
    "\\end{equation*}<br>\n",
    "Dependiendo del valor de $\\beta$:<br>\n",
    "* Usuarios orientados a Precisión: $\\beta$=0.5 (FP perjudica el rendimiento más que FN).\n",
    "* Usuarios orientados a Recall: $\\beta$=2 (FN perjudica el rendimiento más que FP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuacion:  0.9777777777777777\n",
      "Usando SVC lineal: \n",
      " [[402   5]\n",
      " [  5  38]]\n",
      "Exactitud: 0.98\n",
      "Precision: 0.88\n",
      "Recall: 0.88\n",
      "F1 score: 0.88\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "dataset=load_digits()\n",
    "X,y=dataset.data,dataset.target\n",
    "y[y!=1]=0\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0)\n",
    "\n",
    "svm=SVC(kernel='linear',C=1).fit(X_train,y_train)\n",
    "print('Puntuacion: ',svm.score(X_test,y_test))\n",
    "confusion=confusion_matrix(y_test,svm.predict(X_test))\n",
    "print('Usando SVC lineal: \\n',confusion)\n",
    "\n",
    "print('Exactitud: {:.2f}'.format(accuracy_score(y_test,svm.predict(X_test))))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test,svm.predict(X_test))))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test,svm.predict(X_test))))\n",
    "print('F1 score: {:.2f}'.format(f1_score(y_test,svm.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       not 1       0.99      0.99      0.99       407\n",
      "           1       0.88      0.88      0.88        43\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       450\n",
      "   macro avg       0.94      0.94      0.94       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,svm.predict(X_test),target_names=['not 1','1']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
